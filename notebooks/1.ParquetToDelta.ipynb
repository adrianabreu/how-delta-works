{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64064be6-4161-4642-b58e-043cf918bb7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/26 11:56:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "23/11/26 11:56:40 INFO SparkContext: Starting job: run at DeltaConvert.scala:34\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Got job 58 (run at DeltaConvert.scala:34) with 1 output partitions\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Final stage: ResultStage 102 (run at DeltaConvert.scala:34)\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[147] at run at DeltaConvert.scala:34), which has no missing parents\n",
      "23/11/26 11:56:40 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 103.7 KiB, free 432.6 MiB)\n",
      "23/11/26 11:56:40 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 432.6 MiB)\n",
      "23/11/26 11:56:40 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 0541434f17db:34989 (size: 37.4 KiB, free: 434.1 MiB)\n",
      "23/11/26 11:56:40 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1509\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[147] at run at DeltaConvert.scala:34) (first 15 tasks are for partitions Vector(0))\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0\n",
      "23/11/26 11:56:40 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 264) (0541434f17db, executor driver, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()\n",
      "23/11/26 11:56:40 INFO Executor: Running task 0.0 in stage 102.0 (TID 264)\n",
      "23/11/26 11:56:40 INFO Executor: Finished task 0.0 in stage 102.0 (TID 264). 2106 bytes result sent to driver\n",
      "23/11/26 11:56:40 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 264) in 7 ms on 0541434f17db (executor driver) (1/1)\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool \n",
      "23/11/26 11:56:40 INFO DAGScheduler: ResultStage 102 (run at DeltaConvert.scala:34) finished in 0.014 s\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Job 58 finished: run at DeltaConvert.scala:34, took 0.014754 s\n",
      "The table you are trying to convert is already a delta table\n",
      "23/11/26 11:56:40 INFO InMemoryFileIndex: It took 0 ms to list leaf files for 1 paths.\n",
      "23/11/26 11:56:40 INFO SparkContext: Starting job: isCatalogTable at DeltaConvert.scala:35\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Got job 59 (isCatalogTable at DeltaConvert.scala:35) with 1 output partitions\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Final stage: ResultStage 103 (isCatalogTable at DeltaConvert.scala:35)\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Parents of final stage: List()\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Missing parents: List()\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Submitting ResultStage 103 (MapPartitionsRDD[149] at isCatalogTable at DeltaConvert.scala:35), which has no missing parents\n",
      "23/11/26 11:56:40 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 103.7 KiB, free 432.5 MiB)\n",
      "23/11/26 11:56:40 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 37.4 KiB, free 432.5 MiB)\n",
      "23/11/26 11:56:40 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on 0541434f17db:34989 (size: 37.4 KiB, free: 434.0 MiB)\n",
      "23/11/26 11:56:40 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1509\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 103 (MapPartitionsRDD[149] at isCatalogTable at DeltaConvert.scala:35) (first 15 tasks are for partitions Vector(0))\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0\n",
      "23/11/26 11:56:40 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 265) (0541434f17db, executor driver, partition 0, PROCESS_LOCAL, 4605 bytes) taskResourceAssignments Map()\n",
      "23/11/26 11:56:40 INFO Executor: Running task 0.0 in stage 103.0 (TID 265)\n",
      "23/11/26 11:56:40 INFO Executor: Finished task 0.0 in stage 103.0 (TID 265). 2106 bytes result sent to driver\n",
      "23/11/26 11:56:40 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 265) in 7 ms on 0541434f17db (executor driver) (1/1)\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool \n",
      "23/11/26 11:56:40 INFO DAGScheduler: ResultStage 103 (isCatalogTable at DeltaConvert.scala:35) finished in 0.014 s\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Job 59 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "23/11/26 11:56:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 103: Stage finished\n",
      "23/11/26 11:56:40 INFO DAGScheduler: Job 59 finished: isCatalogTable at DeltaConvert.scala:35, took 0.014469 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import io.delta.tables._\n",
       "res6: io.delta.tables.DeltaTable = io.delta.tables.DeltaTable@6cea34d7\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_73_piece0 on 0541434f17db:34989 in memory (size: 37.4 KiB, free: 434.1 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_63_piece0 on 0541434f17db:34989 in memory (size: 34.6 KiB, free: 434.1 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_74_piece0 on 0541434f17db:34989 in memory (size: 37.4 KiB, free: 434.1 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 0541434f17db:34989 in memory (size: 34.6 KiB, free: 434.2 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_72_piece0 on 0541434f17db:34989 in memory (size: 15.7 KiB, free: 434.2 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_70_piece0 on 0541434f17db:34989 in memory (size: 37.4 KiB, free: 434.2 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManager: Removing RDD 128\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_64_piece0 on 0541434f17db:34989 in memory (size: 34.6 KiB, free: 434.3 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_71_piece0 on 0541434f17db:34989 in memory (size: 35.8 KiB, free: 434.3 MiB)\n",
      "23/11/26 12:18:22 INFO BlockManager: Removing RDD 90\n",
      "23/11/26 12:18:22 INFO BlockManagerInfo: Removed broadcast_69_piece0 on 0541434f17db:34989 in memory (size: 103.4 KiB, free: 434.4 MiB)\n"
     ]
    }
   ],
   "source": [
    "import io.delta.tables._\n",
    "\n",
    "DeltaTable.convertToDelta(spark, \"parquet.`sample_data/user_data`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d39e924-8969-4e84-82b5-18ba4a8dfeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "Delta"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
